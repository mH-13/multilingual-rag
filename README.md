
# Multilingual RAG System  
**Bengali â†” English Retrievalâ€‘Augmented Generation**  
Answers English or Bangla questions over any uploaded **PDF document** corpus (Demo: HSC26 Bangla 1st Paper) via retrieval + LLM.


## ğŸ“œ Contents

- [Multilingual RAG System](#multilingual-rag-system)
  - [ğŸ“œ Contents](#-contents)
  - [Setup Guide](#setup-guide)
  - [Running the System](#running-the-system)
    - [FastAPI REST API](#fastapi-rest-api)
  - [âš“ Architecture Diagrams](#-architecture-diagrams)
    - [Mermaid Diagram](#mermaid-diagram)
    - [ASCIIâ€‘Art Overview](#asciiart-overview)
  - [ğŸ¬ Screenshots \& Sample Output](#-screenshots--sample-output)
  - [Sample Queries \& Outputs](#sample-queries--outputs)
  - [Evaluation Matrix](#evaluation-matrix)
  - [âœ’ï¸ API Documentation](#ï¸-api-documentation)
    - [`GET /ask`](#get-ask)
    - [`POST /admin/upload-pdf`](#post-adminupload-pdf)
  - [ğŸ’¡ Assessment Questions \& Answers](#-assessment-questions--answers)
  - [Roadmap \& Next Steps](#roadmap--next-steps)
  - [ğŸ“„ License](#-license)

---

## Setup Guide

1. **Clone the repository**  
   ```bash
   git clone https://github.com/your-username/multilingual-rag.git
   cd multilingual-rag

2. **Create & activate Python venv (3.10+)**
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate

3. **Install dependencies**
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   pip install python-multipart

4. **Configure API keys & parameters**
   Copy and edit `config.yaml` (in `.gitignore`):
   ```yaml
   rag_api:
     key: YOUR_GROQ_API_KEY

   hf_api:
     token: YOUR_HUGGINGFACE_TOKEN

   summarization:
     max_chars: 500
     summary_threshold: 0.5

   short_term:
     max_turns: 5

## ğŸ“š Project Structure & Components

```
multilingual-rag/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Original PDF(s)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ raw_text_*.txt
â”‚       â”œâ”€â”€ clean_text_*.txt
â”‚       â””â”€â”€ chunks_*/*     # chunk_0000.txt, etc.
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ chunks_*.json      # Embedding vectors + metadata
â”‚   â””â”€â”€ faiss_*.index      # FAISS indexes
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py  # optional text-based extractor
â”‚   â”‚   â””â”€â”€ ocr_parser.py  # Tesseract OCR pipeline
â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â””â”€â”€ cleaner.py     # Unicode & junk removal
â”‚   â”œâ”€â”€ chunking/
â”‚   â”‚   â””â”€â”€ char_chunker.py# simple char-based splitter
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embedder.py    # HF InferenceClient embedding
â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â””â”€â”€ indexer.py     # FAISS build/load
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â””â”€â”€ retriever.py   # CLI retrieval tester
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ rag_pipeline.py# RAGPipeline with memory & summarization
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ app.py         # FastAPI main
â”‚   â”‚   â””â”€â”€ admin.py       # Background PDF ingestion
â”‚   â””â”€â”€ eval/
â”‚       â””â”€â”€ evaluate.py    # Automated evaluation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_queries.yaml  # Ground-truth Q&A pairs
â”œâ”€â”€ config.yaml            # Userâ€supplied keys & params
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md              # This file
â””â”€â”€ .gitignore
```

## ğŸ›’ Used Tools, Libraries, Packages

| Component                  | Library / Tool                        | Role                                  |
| -------------------------- | ------------------------------------- | ------------------------------------- |
| PDF â†’ Text Extraction      | `pdf2image` + `pytesseract`           | OCR extraction for Bangla fidelity    |
| Text Cleaning              | Python `re`, `unicodedata`            | Unicode NFC, remove junk & page nums  |
| Chunking                   | Python stdlib                         | Charâ€‘based splitting with overlap     |
| Embedding                  | `huggingface-hub` (`InferenceClient`) | Multilingual MiniLM embeddings        |
| Vector DB                  | `faiss-cpu`                           | Local, inner-product index            |
| Memory & RAG Orchestration | `groq` SDK                            | Chatâ€‘based summarization & QA         |
| REST API                   | `FastAPI`, `uvicorn`                  | HTTP endpoints & autoâ€‘docs            |
| Evaluation                 | `pyyaml`, `pytest`                    | Groundâ€‘truth tests & accuracy metrics |



## Data Processing & Pipeline Steps

1. **OCR Extraction**
   ```bash
   python src/extract/ocr_parser.py \
     data/raw/HSC26_Bangla_1st_paper.pdf \
     data/processed/raw_text_HSC26.txt
   ```

2. **Cleaning**
   ```bash
   python src/preprocess/cleaner.py \
     data/processed/raw_text_HSC26.txt \
     data/processed/clean_text_HSC26.txt
   ```

3. **Chunking**

   ```bash
   python src/chunking/char_chunker.py \
     data/processed/clean_text_HSC26.txt \
     data/processed/chunks_HSC26/ \
     --max-chars 2000 --overlap 200
   ```

4. **Embedding**

   ```bash
   python src/embeddings/embedder.py \
     --chunks-dir data/processed/chunks_HSC26 \
     --out embeddings/chunks_HSC26.json \
     --batch-size 10
   ```

5. **Indexing**

   ```bash
   python src/vector_store/indexer.py \
     --embeddings embeddings/chunks_HSC26.json \
     --index-out embeddings/faiss_HSC26.index
   ```

6. **Retrieval (CLI)**

   ```bash
   python src/retrieval/retriever.py \
     --index embeddings/faiss_HSC26.index \
     --meta embeddings/faiss_HSC26.index.meta.json \
     --query "à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾à¦° à¦—à§à¦°à§à¦¤à§à¦¬ à¦•à§€?" --top-k 5
   ```

7. **RAG Pipeline (CLI)**

   ```bash
   python src/rag/rag_pipeline.py \
     --query "à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾à¦° à¦—à§à¦°à§à¦¤à§à¦¬ à¦•à§€?" --top-k 5
   ```

## Running the System

### FastAPI REST API

1. **Start server**

   ```bash
   uvicorn src.api.app:app --reload
   ```

2. **Interactive docs**
   Navigate to [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

3. **Query endpoint**

   ```bash
   curl -G http://127.0.0.1:8000/ask \
     --data-urlencode 'q=à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?' \
     --data-urlencode 'k=5'
   ```

4. **Ingest new PDFs (background)**

   ```bash
   curl -X POST http://127.0.0.1:8000/admin/upload-pdf \
     -F "file=@/path/to/another_doc.pdf"
   ```

## âš“ Architecture Diagrams

### Mermaid Diagram

```mermaid
flowchart LR
    A[PDF (HSC26 Bangla 1st Paper)] --> B[OCR Extraction]
    B --> C[Text Cleaning]
    C --> D[Chunking (charâ€‘based)]
    D --> E[Embedding (HF MiniLM)]
    E --> F[FAISS Index]
    F --> G[Retrieval]
    G --> H[RAG Pipeline<br/>(with Memory & Summarization)]
    H --> I[Groq LLM]
    H --> J[FastAPI Endpoint]
    I -- "Answer" --> J
```

### ASCIIâ€‘Art Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF       â”‚â”€â”€â”€â”€â–ºâ”‚   Clean &    â”‚â”€â”€â”€â”€â–ºâ”‚  FAISS     â”‚â”€â”€â”€â”€â–ºâ”‚   LLM      â”‚
â”‚ (HSC26)     â”‚     â”‚   Chunk      â”‚     â”‚  Index     â”‚     â”‚ (Groq)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ FastAPI Endpoint  â”‚
                 â”‚   (/ask, /admin)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## ğŸ¬ Screenshots & Sample Output

![Swagger UI](docs/images/swagger_ui.png)
*Swagger UI showing `/ask` and `/admin/upload-pdf` endpoints.*

![Sample Response](docs/images/sample_response.gif)
*GIF of a Bangla query and JSON response.*



## Sample Queries & Outputs

| Question (Bangla)                               | Answer  |
| ----------------------------------------------- | ------- |
| à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?         |  |
| à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡? |  |
| à¦¬à¦¿à§Ÿà§‡à¦° à¦¸à¦®à§Ÿ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à§Ÿà¦¸ à¦•à¦¤ à¦›à¦¿à¦²?           |  |

| Question (English)                         | Answer (English)                                                                                                                 |
| ------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------- |
| What is the importance of Bangla language? |     |
| Why do people read stories?                |  |


## Evaluation Matrix

Running `python src/eval/evaluate.py` yields:

```
Q: à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?
Expected: à¦¶à§à¦®à§à¦­à§à¦¨à¦¾à¦¥
Got: 
Result: 

Q: à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?
Expected: à¦®à¦¾à¦®à¦¾à¦•à§‡
Got:
Result: 

Q: à¦¬à¦¿à§Ÿà§‡à¦° à¦¸à¦®à§Ÿ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à§Ÿà¦¸ à¦•à¦¤ à¦›à¦¿à¦²?
Expected: à§§à§« à¦¬à¦›à¦°
Got: 
Result: 

Q: What is the importance of Bangla language?
Expected: cultural and literary heritage
Got: 
Result: 

Q: Why do people read stories?
Expected: communication
Got: 
Result: 

Overall Accuracy: 5/5 = 
```


## âœ’ï¸ API Documentation

### `GET /ask`

* **Params**

  * `q` (string): question in Bangla or English
  * `k` (int, default 5): # of context snippets (1â€“10)

* **Response**

  ```json
  {
    "answer": "<generated answer>",
    "contexts": [
      { "id": "chunk_0003", "score": 0.73, "text": "â€¦" }, â€¦
    ]
  }
  ```

### `POST /admin/upload-pdf`

* **Form**: `file` field (PDF)
* **Returns** (202)

  ```json
  { "detail": "Ingestion of 'filename.pdf' started in background." }
  ```


## ğŸ’¡ Assessment Questions & Answers

1. **What method/library for text extraction?**

   * **Used**: Tesseract OCR via `pdf2image` + `pytesseract` in `ocr_parser.py`.
   * **Why**: `pdfplumber` and `PyMuPDF` garbled Bangla diacritics and ligatures; OCR produced clean Unicode.
   * **Challenges**: Removing page numbers, headers, stray English letters, and retaining correct line breaks.

2. **What chunking strategy?**

   * **Approach**: Characterâ€‘based (\~2â€¯000 chars) with 10â€¯% overlap in `char_chunker.py`.
   * **Rationale**: Languageâ€‘agnostic, no heavy tokenizer dependency, predictable chunk size under token limits, preserves semantic continuity via overlap.

3. **What embedding model?**

   * **Model**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` via HF InferenceClient.
   * **Why**: Small (<100â€¯MB), free Inference API, supports 100+ languages including Bangla.
   * **Captures**: Semantic similarity across English & Bangla, good for crossâ€‘lingual retrieval.

4. **How compare query with chunks?**

   * **Vector similarity**: Cosine via FAISS `IndexFlatIP` on L2â€‘normalized embeddings.
   * **Storage**: FAISS local CPU index, zero config, instant nearestâ€‘neighbor search.

5. **Ensuring meaningful comparison?**

   * **Summarization & truncation**: Caps context size, reduces noise.
   * **Shortâ€‘term chat memory**: Maintains conversational context.
   * **If vague query**: Might retrieve unrelated chunks; future work: query expansion, reranking by LLM.

6. **Are results relevant?**

   * **Current**: Low exactâ€‘match, but answers are semantically coherent.
   * **Improvements**: Finer chunking (sentenceâ€‘aware), larger/fineâ€‘tuned embeddings, LLMâ€‘based reranking of retrieved chunks.



## Roadmap & Next Steps

* Fineâ€‘tune embedding model on Bangla QA pairs
* Sentenceâ€‘based or LangChain chunking for richer context
* Reranking topâ€‘K chunks via LLM before answer
* Streaming `/ask/stream` responses
* Bengali TTS (e.g. Bark) for audio answers


## ğŸ“„ License
MIT Â© 2025 \[Mehedi Hasan] 
